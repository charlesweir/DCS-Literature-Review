{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowballing, for rounds 2 and above\n",
    "\n",
    "This takes each newly-coded spreadsheet of papers and queries further 'related articles' from the newly selected papers. Each time it runs it retrieves a new set of candidates and adds them to the list, saving them to a new spreadsheet.\n",
    "\n",
    "Before starting, the previous spreadsheet, PapersToCode.xlsx (starting with N=2), should be double coded, adding coding values (7 or above means 'accept') in the column for each coder (C and P) and in the AgreedScore column (the result of coder discussion). Save the result as CodedPapers.xlsx.\n",
    "\n",
    "Change the coder names in the FirstStep and Analysis notebook if desired.\n",
    "\n",
    "Copyright &copy; 2021.   \n",
    "Shared under the Apache 2.0 License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We upped this count after round 3 to 19 (see Analysis notebook)\n",
    "RequiredAnnualCount=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "VD37eEggwAcN",
    "outputId": "016164cc-d8df-42fe-8797-48482a2513bb"
   },
   "outputs": [],
   "source": [
    "# !pip install google-search-results\n",
    "from serpapi import GoogleScholarSearch\n",
    "from ScholarUtils import GetPapers, GetPaper, WellCitedPapers, InitScholar, RelatedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "colab_type": "code",
    "id": "bg0FZIzozs9Q",
    "outputId": "7f97b83a-f557-46f8-c472-ce361aa121f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "# Reload ScholarUtils every time before executing code \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "InitScholar(\"APIKey.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoringSpreadsheet=\"CodedPapers.xlsx\"\n",
    "previousPapersDf=(pd.read_excel(scoringSpreadsheet, index_col=0,\n",
    "                                # Want Key as string, not number, to match WellCitedPapers() output:\n",
    "                              dtype={'Key':np.str_})\n",
    "                         )\n",
    "CurrentRound=previousPapersDf.Round.max()\n",
    "CurrentRound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the accepted papers from the latest round of coding:\n",
    "papersToFollowDf=previousPapersDf.query('Round=={} and AgreedScore > 6'.format(CurrentRound))\n",
    "print(len(papersToFollowDf))\n",
    "papersToFollowDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving 101 papers for {'q': 'related:PB-i-ducMAkJ:scholar.google.com/'}\n",
      "Retrieving 101 papers for {'q': 'related:XdGBzFFCLnYJ:scholar.google.com/'}\n",
      "Retrieving 101 papers for {'q': 'related:Bqb9fheoRCwJ:scholar.google.com/'}\n",
      "Retrieving 101 papers for {'q': 'related:VohQc7PQG0YJ:scholar.google.com/'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "404"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask Google for the 'related publications' for each newly coded item (takes a long time)\n",
    "# Concatenate returned lists...\n",
    "newPapers = [foundPaper for relatedPaper in papersToFollowDf.itertuples()\n",
    "                 for foundPaper in GetPapers(RelatedQuery(relatedPaper.Related))\n",
    "            ] \n",
    "len(newPapers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"papersFound.p\", \"rb\" ) as inFile:\n",
    "    allPapers=pickle.load( inFile ) + newPapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Google queries take a long time and can cost money. \n",
    "# We save the results as 'pickle' dumps, \n",
    "# Can also 'comment out' the slow parts by changing the cell type to 'Raw NB Convert'; \n",
    "# to redo the queries, convert them back again to Code.\n",
    "\n",
    "with open( \"papersFound.p\", \"wb\" ) as outFile:\n",
    "    pickle.dump( allPapers, outFile )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many unique papers so far?\n",
    "\n",
    "pd.Series([paper['result_id'] for paper in allPapers]).unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newPapersDf=(WellCitedPapers(newPapers, requiredAnnualCount=RequiredAnnualCount)\n",
    "           .reindex(columns=previousPapersDf.columns, fill_value='') # Add in the extra classification columns.\n",
    "            .assign(Round=CurrentRound+1)\n",
    "          )\n",
    "len(newPapersDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allPapersSoFarDf=(pd.concat([previousPapersDf, newPapersDf]) # Keep already coded papers - don't want to recode.\n",
    "                .drop_duplicates(subset=['Key'])  # Only want new ones - this keeps the earlier entries.\n",
    "                .reset_index(drop=True)           # Don't need to keep the old numbering.\n",
    "               )\n",
    "allPapersSoFarDf.to_excel('PapersToCode.xlsx')\n",
    "len(allPapersSoFarDf)\n",
    "#allPapersSoFarDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open PapersToCode.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8808c4021c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ScholarUtils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NLP_example_clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
